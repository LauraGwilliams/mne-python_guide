# MNE Script #
 

# STEP 1 # -- IMPORT DEPENDENCIES # PAGE 12 #

import mne
import os
#import surfer
import pylab as pl
from scipy import io
from mne import fiff
from mne.viz import plot_evoked
from mne.epochs import combine_event_ids
from mne.fiff import Raw
from mne.fiff import Evoked
from mne.minimum_norm import apply_inverse, read_inverse_operator
from mne.preprocessing.ica import ICA
from eelbrain.lab import Dataset, Var, gui
from eelbrain.lab import load

os.environ['MNE_ROOT'] = '/Applications/MNE-<your version of MNE here>'		# make sure this line includes the exact version of MNE that you are using! #
os.environ['SUBJECTS_DIR'] = '/<path_to_mri_folder>'
os.environ['FREESURFER_HOME'] = '/Applications/freesurfer/'

# STEP 2 # -- ENTER ANALYSIS DETAILS # PAGE 12 #

participant = '<participant_code>'      # you need to make sure to change this each time you run the script #
experiment = '<experiment_name>'        # use the same name here as in your files #
root = '<path_to_experiment_folder>'	# the experiment folder should contain both an 'MEG' folder for your all your participant's data and an 'MRIs' folder where the scaled fsaverage or MRI for each subject will be housed.

meg_root = root + '/MEG'             	# if your folders are named correctly, these three should remain untouched #   
subjects_dir = root + '/MRIs'           
stc_path = root + '/stc'


# STEP 3 # -- CONVERT FILES TO .FIF FORMAT # PAGE 13 #

mne.gui.kit2fiff()                      			# make sure you are using the Qt4 backend in 'preferences' #

# STEP 4 # -- TRANSFORMATION MATRIX # PAGE 14 #

mne.gui.coregistration()                			# remember that the 'subjects_dir' is the MRI folder #




###########################################################################################################
## CHANGE THE BACKEND TO WX AND RE-RUN STEPS 1 & 2. Change working directory to experiment folder again. ##
###########################################################################################################




# STEP 5 # -- READ THE DATA # PAGE 16 # 

raw = mne.fiff.Raw( participant + '/' + participant + '_' + experiment + '-raw.fif', preload = True)
print raw
raw.info


# STEP 6 # -- LOOK AT THE DATA TO FIND BAD CHANNELS # PAGE 17 #

raw.plot()                              			# press the down arrow to cycle through channels #



# STEP 7 # -- DEFINE BAD CHANNELS # PAGE 18 #

raw.info['bads'] += ['MEG 017']              	# this is +1 to what you'll see on the data acquisition screen #



# STEP 8 # -- LOW PASS FILTER # PAGE 18 #

raw.filter(0, 40, method = 'iir')               	# low pass filter at 40hz #

raw.save( participant + '/' + participant + '_' + experiment + '_lp-raw.fif', overwrite = True)




# STEP 9 # -- LOAD EVENTS # PAGE 18 #

events = mne.find_events(raw, stim_channel = 'STI 014')

print events                                		# check you have the expected number of events #

mne.write_events( participant + '/' + participant + '_events.fif',events)



# STEP 10 # -- DEFINE CONDITIONS # PAGE 19 # 

event_id = dict(<cond1> = 1, <cond2> = 2, <cond3> = 16, <cond4> = 32)  
                                        # state which conditions match with which triggers #

event_id                                # check all of your conditions have been labelled correctly.
                        		

# STEP 11 # -- DEFINE EPOCHS # PAGE 19 #

tmin = -0.1         								# pre stimulis interval (in seconds) #
tmax = 1.2          								# post stimulus interval #

picks = mne.fiff.pick_types(raw.info, meg= True, stim = False, exclude = 'bads')    # channels to use in epochs #
baseline = (None, 0)                                                                # what to use as baseline comparison - here it's pre-stim interval #
epochs = mne.Epochs(raw, events, event_id,tmin, tmax, proj = True, picks = picks, baseline=baseline, preload = True)

print epochs

epochs.save( participant + '/' + participant + '_epoch-av.fif')


# STEP 12 #  --  REJECT BLINKS FROM EPOCHS # PAGE 20 #

# set up the blink GUI #

ds = Dataset()
ds['epochs'] = epochs
ds['trigger'] = Var(np.ones(ds.n_cases))
g = gui.SelectEpochs(ds, data='epochs', path = root + experiment + '/' + participant + '/' + participant + '_rejected.txt') # path to save rejections #
g.set_vlim(2e-12)						# threshold of automatic detection #
g.set_plot_style(mark = ['087', '130'])				# view the channels close to the eye over the top of the channel average #
g.auto_reject(2e-12, False, None)


# save the result to file #

blink = load.tsv( participant + '/' + participant + '_rejected.txt')
idx = blink['accept'].x
epochs = epochs[idx]		# save epochs without the rejections #

epochs                          # make a note of how many per condition were rejected #



# STEP 13 # -- DEFINE THE EPOCHS FOR EACH CONDITION ## PAGE 21 #


# STEP 13A # -- COMBINE CONDITIONS # PAGE 22 #

#### -------#### -------#### -------

# ((OPTIONAL)) #
# ((IF MANY TRIGGERS = ONE CONDITION))  #
# IF NOT RELEVANT, SKIP TO STEP 13B #
# combine conditions

combine_event_ids(epochs, ['cond1a', 'cond1b', 'cond1c'], {'cond1': 10}, copy = False)
combine_event_ids(epochs, ['cond2a', 'cond2b', 'cond2c'], {'cond2': 20}, copy = False)
combine_event_ids(epochs, ['cond3a', 'cond3b', 'cond3c'], {'cond3': 30}, copy = False)
combine_event_ids(epochs, ['cond4a', 'cond4b', 'cond4c'], {'cond4': 40}, copy = False)

#### -------#### -------#### -------
												# this is for if you have a number of triggers which correspond to a single condition #
												# if this is not the case, please skip this step #
# STEP 13B # -- MAKE EPOCHS PER CONDITION # PAGE 22 #

epochs['<cond1>'].get_data()
epochs_<cond1> = epochs['<cond1>']
epochs['<cond2>'].get_data()
epochs_<cond2> = epochs['<cond2>']
epochs['<cond3>'].get_data()
epochs_<cond3> = epochs['<cond3>']
epochs['<cond4>'].get_data()
epochs_<cond4> = epochs['<cond4>']



# STEP 14 # -- READ EPOCHS AND MAKE EVOKED # PAGE 22 #


evoked = epochs.average()
evoked.save( participant + '/' + participant + '-evoked-av.fif')


# STEP 14b # -- EVOKED RESPONSE FOR EACH CONDITION # PAGE 22 #


evoked_<cond1> = epochs_<cond1>['<cond1>'].average()
evoked_<cond1>.save( participant + '/' + participant + '<cond1>-evoked-av.fif')

evoked_<cond2> = epochs_<cond2>['<cond2>'].average()
evoked_<cond2>.save( participant + '/' + participant + '<cond2>-evoked-av.fif')

evoked_<cond3> = epochs_<cond3>['<cond3>'].average()
evoked_<cond3>.save( participant + '/' + participant + '<cond3>-evoked-av.fif')

evoked_<cond4> = epochs_<cond4>['<cond4>'].average()
evoked_<cond4>.save( participant + '/' + participant + '<cond4>-evoked-av.fif')



# STEP 15 # -- COVARIANCE MATRIX # PAGE 23 #

cov = mne.cov.compute_covariance(epochs, 0)
cov = mne.cov.regularize(cov, evoked.info, mag=0.05, grad = 0.05, proj = True, exclude = 'bads')

mne.write_cov( participant + '/' + participant + '_cov.fif', cov)


# STEP 16 # -- FORWARD SOLUTION # PAGE 23 #

info = participant + '/' + participant + '-evoked-av.fif'
mri = participant + '/' + participant + '-trans.fif'
src = subjects_dir + '/' + participant + '/bem/' + participant + '-ico-4-src.fif'
bem = subjects_dir + '/' + participant + '/' + participant + '/bem/' + participant + '-inner_skull-bem-sol.fif'
fname = participant + '/' + participant + '_forward.fif'

fwd = mne.make_forward_solution(info = info, mri = mri, src = src, bem = bem, fname = fname, meg = True, eeg = False, overwrite = True)

														# here, information from the coregistration is used to compute the forward solution #
															


# STEP 17 # -- INVSERSE OPERATOR # PAGE 23 #

inv = mne.minimum_norm.make_inverse_operator(evoked.info, fwd, cov, loose = None, depth = None, fixed = False)
													# this is for a free orientation. If you want to change to fixed, include a depth parameter and say 'True' to fixed' #
mne.minimum_norm.write_inverse_operator( participant + '/' + participant + '_inv.fif', inv)



# STEP 16 # -- APPLY INVERSE TO GET SOURCE TIME ESTIMATES # PAGE 24 #

snr = 2.0                     						# signal to noise ratio #
lambda2 = 1.0 / snr ** 2.0
method = 'MNE'              						# how do you want to apply the inverse solution? #



# apply inverse operator for each condition:

stc_<cond1> = mne.minimum_norm.apply_inverse(evoked_<cond1>, inv, method = method, lambda2 = lambda2, pick_ori = None)
stc_<cond2> = mne.minimum_norm.apply_inverse(evoked_<cond2>, inv, method = method, lambda2 = lambda2, pick_ori = None)
stc_<cond3> = mne.minimum_norm.apply_inverse(evoked_<cond3>, inv, method = method, lambda2 = lambda2, pick_ori = None)
stc_<cond4> = mne.minimum_norm.apply_inverse(evoked_<cond4>, inv, method = method, lambda2 = lambda2, pick_ori = None)


# and save them

stc_<cond1>.save( stc_path + '/cond1_<cond1>/' + participant + '.fif')
stc_<cond2>.save( stc_path + '/cond2_<cond2>/' + participant + '.fif')
stc_<cond3>.save( stc_path + '/cond3_<cond3>/' + participant + '.fif')
stc_<cond4>.save( stc_path + '/cond4_<cond4>/' + participant + '.fif')
